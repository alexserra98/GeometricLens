{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics.utils import hidden_states_collapse\n",
    "from metrics.query import DataFrameQuery\n",
    "from common.tensor_storage import TensorStorage\n",
    "from common.metadata_db import MetadataDB\n",
    "from common.utils import *\n",
    "from metrics.utils import  exact_match, angular_distance\n",
    "\n",
    "#from sklearn.feature_selection import mutual_info_regression MISSIN?\n",
    "from dadapy.data import Data\n",
    "\n",
    "from pathlib  import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dataframes(db) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate in a dataframe the hidden states of all instances\n",
    "    ----------\n",
    "    hidden_states: pd.DataFrame(num_instances, num_layers, model_dim)\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(\"SELECT * FROM metadata\", db.conn)\n",
    "    df[\"train_instances\"] = df[\"train_instances\"].astype(str)\n",
    "    df.drop(columns=[\"id\"],inplace = True)\n",
    "    #import pdb; pdb.set_trace()\n",
    "    df.drop_duplicates(subset = [\"id_instance\"],inplace = True, ignore_index = True) # why there are duplicates???\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_retrieve(dict_query):\n",
    "    query = DataFrameQuery(dict_query)\n",
    "    hidden_states,logits, hidden_states_df= hidden_states_collapse(df_hiddenstates=metadata_df,query=query,tensor_storage=tensor_storage)\n",
    "    return hidden_states,logits,hidden_states_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructing_labels(label: str, hidden_states_df: pd.DataFrame, hidden_states: np.ndarray) -> np.ndarray:\n",
    "    labels_literals = hidden_states_df[label].unique()\n",
    "    labels_literals.sort()\n",
    "    \n",
    "    map_labels = {class_name: n for n,class_name in enumerate(labels_literals)}\n",
    "    \n",
    "    label_per_row = hidden_states_df[label].reset_index(drop=True)\n",
    "    label_per_row = np.array([map_labels[class_name] for class_name in label_per_row])[:hidden_states.shape[0]]\n",
    "    \n",
    "    return label_per_row, map_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PATH = Path(\"/orfeo/scratch/dssc/zenocosini/mmlu_result/\")\n",
    "result_path = Path(_PATH,\"log_reg\")\n",
    "result_path.mkdir(exist_ok=True,parents=True)\n",
    "metadata_db = MetadataDB(_PATH / \"metadata.db\")\n",
    "metadata_df = set_dataframes(metadata_db)\n",
    "tensor_storage = TensorStorage(Path(_PATH, \"tensor_files\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_query = { \"method\":\"last\",\n",
    "              \"model_name\":\"meta-llama/Llama-2-7b-hf\",\n",
    "              \"train_instances\": 0}\n",
    "query = DataFrameQuery(dict_query)\n",
    "df_hiddenstates = query.apply_query(metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test sets for each subject\n",
    "train_frames = []\n",
    "test_frames = []\n",
    "\n",
    "for subject in df_hiddenstates['dataset'].unique():\n",
    "    subject_data = df_hiddenstates[df_hiddenstates['dataset'] == subject]\n",
    "    train, test = train_test_split(subject_data, test_size=0.2, random_state=42)\n",
    "    train_frames.append(train)\n",
    "    test_frames.append(test)\n",
    "\n",
    "train_df = pd.concat(train_frames)\n",
    "test_df = pd.concat(test_frames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tensor retrieval took: 144.9542293548584\n",
      "\n",
      " Tensor retrieval took: 1.6496326923370361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, _, df_train = hidden_states_collapse(df_hiddenstates=train_df,tensor_storage=tensor_storage)\n",
    "X_test, _, df_test = hidden_states_collapse(df_hiddenstates=test_df,tensor_storage=tensor_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'A', ..., 'B', '', ''], dtype='<U10')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_df['std_pred']\n",
    "np.asarray(y_train.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tensor retrieval took: 6.083222389221191\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/dssc/zenocosini/miniconda3/envs/mcqa/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tensor retrieval took: 2.1171014308929443\n",
      "\n",
      "The accuracy of the logistic regression model is: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Preparing the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)  # Increased max_iter to ensure convergence\n",
    "\n",
    "# Training the model\n",
    "X_train, _, train_df = hidden_states_collapse(df_hiddenstates=train_df,tensor_storage=tensor_storage)\n",
    "y_train = np.asarray(train_df['std_pred'].tolist())\n",
    "model.fit(X_train[:,-1,:], y_train)\n",
    "\n",
    "# Testing the model\n",
    "X_test, _, test_df = hidden_states_collapse(df_hiddenstates=test_df,tensor_storage=tensor_storage)\n",
    "y_test = np.asarray(test_df['std_pred'].tolist())\n",
    "predictions = model.predict(X_test[:,-1,:])\n",
    "\n",
    "# Calculating the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'The accuracy of the logistic regression model is: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/orfeo/scratch/dssc/zenocosini/mmlu_result/log_reg/test_model.joblib']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, Path(result_path, \"test_model.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/orfeo/scratch/dssc/zenocosini/mmlu_result/log_reg/test\n"
     ]
    }
   ],
   "source": [
    "!ls /orfeo/scratch/dssc/zenocosini/mmlu_result/log_reg/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tensor retrieval took: 9.455770254135132\n",
      "\n",
      " Tensor retrieval took: 1.6556823253631592\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m weights \u001b[38;5;241m=\u001b[39m compute_class_weight(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, classes\u001b[38;5;241m=\u001b[39mclasses, y\u001b[38;5;241m=\u001b[39mtrain_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monly_ref_pred\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     13\u001b[0m class_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(classes, weights))\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Preparing the logistic regression model\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mLogisticRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Increased max_iter to ensure convergence\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Training the model\u001b[39;49;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Train set\n",
    "X_train, _, train_df = hidden_states_collapse(df_hiddenstates=train_df,tensor_storage=tensor_storage)\n",
    "y_train = np.asarray(train_df['only_ref_pred'].tolist())\n",
    "# Test set \n",
    "X_test, _, test_df = hidden_states_collapse(df_hiddenstates=test_df,tensor_storage=tensor_storage)\n",
    "y_test = np.asarray(test_df['only_ref_pred'].tolist())\n",
    "\n",
    "models = []\n",
    "performance_per_layer = []\n",
    "\n",
    "classes = train_df['only_ref_pred'].unique()\n",
    "weights = compute_class_weight('balanced', classes=classes, y=train_df['only_ref_pred'])\n",
    "class_weight = dict(zip(classes, weights))\n",
    "\n",
    "for layer in range(X_train.shape[1]):\n",
    "    # Preparing the logistic regression model\n",
    "    model = LogisticRegression(max_iter=1000, class_weight=class_weight)  # Increased max_iter to ensure convergence\n",
    "    \n",
    "    # Training the model\n",
    "    model.fit(X_train[:,layer,:], y_train)\n",
    "    \n",
    "    # Testing the model\n",
    "    predictions = model.predict(X_test[:,layer,:])\n",
    "    \n",
    "    # Calculating the accuracy of the model\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "    joblib.dump(model, Path(result_path, f\"model_layer{layer}.joblib\"))\n",
    "    print(f'The accuracy of the logistic regression model at layer {layer} is: {accuracy:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
