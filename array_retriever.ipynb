{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics.utils import hidden_states_collapse\n",
    "from metrics.query import DataFrameQuery\n",
    "from common.tensor_storage import TensorStorage\n",
    "from metrics.utils import  exact_match\n",
    "#from sklearn.feature_selection import mutual_info_regression MISSIN?\n",
    "from dadapy.data import Data\n",
    "\n",
    "from pathlib  import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from common.metadata_db import MetadataDB\n",
    "from common.utils import *\n",
    "from pathlib import Path\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dataframes(db) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate in a dataframe the hidden states of all instances\n",
    "    ----------\n",
    "    hidden_states: pd.DataFrame(num_instances, num_layers, model_dim)\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(\"SELECT * FROM metadata\", db.conn)\n",
    "    df[\"train_instances\"] = df[\"train_instances\"].astype(str)\n",
    "    df.drop(columns=[\"id\"],inplace = True)\n",
    "    #import pdb; pdb.set_trace()\n",
    "    df.drop_duplicates(subset = [\"id_instance\"],inplace = True, ignore_index = True) # why there are duplicates???\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_retrieve(dict_query):\n",
    "    query = DataFrameQuery(dict_query)\n",
    "    hidden_states,_, hidden_states_df= hidden_states_collapse(metadata_df,query,tensor_storage)\n",
    "    return hidden_states,hidden_states_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def constructing_labels(label: str, hidden_states_df: pd.DataFrame, hidden_states: np.ndarray) -> np.ndarray:\n",
    "      labels_literals = hidden_states_df[label].unique()\n",
    "      labels_literals.sort()\n",
    "      \n",
    "      map_labels = {class_name: n for n,class_name in enumerate(labels_literals)}\n",
    "      \n",
    "      label_per_row = hidden_states_df[label].reset_index(drop=True)\n",
    "      label_per_row = np.array([map_labels[class_name] for class_name in label_per_row])[:hidden_states.shape[0]]\n",
    "      \n",
    "      return label_per_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PATH = Path(\"/orfeo/scratch/dssc/zenocosini/mmlu_result\")\n",
    "result_path = Path(_PATH,\"diego\")\n",
    "result_path.mkdir(exist_ok=True,parents=True)\n",
    "metadata_db = MetadataDB(_PATH / \"metadata.db\")\n",
    "metadata_df = set_dataframes(metadata_db)\n",
    "tensor_storage = TensorStorage(Path(_PATH, \"tensor_files\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tensor retrieval took: 156.5567717552185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = list(metadata_df[\"dataset\"].unique())\n",
    "dict_query = {\"dataset\":datasets, \n",
    "              \"method\":\"last\",\n",
    "              \"model_name\":\"meta-llama/Llama-2-7b-hf\",\n",
    "              \"train_instances\": 5}\n",
    "hidden_states, hidden_states_df = tensor_retrieve(dict_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-7b-base-5shot.npy  subjects.npy\n"
     ]
    }
   ],
   "source": [
    "! ls /orfeo/scratch/dssc/zenocosini/mmlu_result/diego/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(Path(result_path,\"llama-7b-base-5shot\"), hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = constructing_labels(\"dataset\",hidden_states_df, hidden_states)\n",
    "np.save(Path(result_path,\"subjects-base\"),labels)\n",
    "labels = constructing_labels(\"only_ref_pred\",hidden_states_df, hidden_states)\n",
    "np.save(Path(result_path,\"letter-base\"),labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_nn_matrix = {}\n",
    "for layer in [6,15,18,29,31]:\n",
    "    data = Data(hidden_states[:,layer,:])\n",
    "    data.compute_distances(maxk=150)\n",
    "    dict_nn_matrix[layer] = (data.distances,data.dist_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(result_path,\"llama-7b-base-5shot-dist-matrix.pkl\"),\"wb\") as f:\n",
    "    pickle.dump(dict_nn_matrix,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tensor retrieval took: 161.6436107158661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = list(metadata_df[\"dataset\"].unique())\n",
    "dict_query = {\"dataset\":datasets, \n",
    "              \"method\":\"last\",\n",
    "              \"model_name\":\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "              \"train_instances\": 5}\n",
    "hidden_states, hidden_states_df = tensor_retrieve(dict_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(Path(result_path,\"llama-7b-chat-5shot\"), hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = constructing_labels(\"dataset\",hidden_states_df, hidden_states)\n",
    "np.save(Path(result_path,\"subjects-chat\"),labels)\n",
    "labels = constructing_labels(\"only_ref_pred\",hidden_states_df, hidden_states)\n",
    "np.save(Path(result_path,\"letter-chat\"),labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_nn_matrix = {}\n",
    "for layer in [6,15,18,29,31]:\n",
    "    data = Data(hidden_states[:,layer,:])\n",
    "    data.compute_distances(maxk=150)\n",
    "    dict_nn_matrix[layer] = (data.distances,data.dist_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(result_path,\"llama-7b-chat-5shot-dist-matrix.pkl\"),\"wb\") as f:\n",
    "    pickle.dump(dict_nn_matrix,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_matches = metadata_df.apply(lambda r: exact_match(r[\"std_pred\"], r[\"letter_gold\"]), axis=1)\n",
    "metadata_df[\"exact_match\"] = exact_matches\n",
    "metadata_df_correct = metadata_df[metadata_df[\"method\"]==\"last\"].copy()\n",
    "\n",
    "#WHATCH OUT: some instance in medicine realated subject are repeated.\n",
    "metadata_df_correct[\"id_instance\"] = metadata_df_correct.apply(lambda r: r[\"id_instance\"][:92]+r[\"id_instance\"][-1], axis=1)\n",
    "metadata_df_correct.drop_duplicates(subset=[\"id_instance\"],inplace = True)\n",
    "metadata_df_correct[\"id_instance\"] = metadata_df_correct.apply(lambda r: r[\"id_instance\"][:64], axis=1)\n",
    "\n",
    "metadata_df_correct.reset_index(inplace=True)\n",
    "metadata_df_correct.drop(columns=[\"index\"],inplace=True)\n",
    "\n",
    "#creating pivot table\n",
    "metadata_df_correct['match_comb'] = metadata_df_correct.apply(lambda row: f\"{row['model_name']}_{row['train_instances']}\", axis=1)\n",
    "pivot_df = metadata_df_correct.pivot(index='id_instance', columns='match_comb', values='exact_match')\n",
    "pivot_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_instance', 'meta-llama/Llama-2-7b-chat-hf_0',\n",
       "       'meta-llama/Llama-2-7b-chat-hf_2', 'meta-llama/Llama-2-7b-chat-hf_5',\n",
       "       'meta-llama/Llama-2-7b-hf_0', 'meta-llama/Llama-2-7b-hf_2',\n",
       "       'meta-llama/Llama-2-7b-hf_5'],\n",
       "      dtype='object', name='match_comb')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   meta-llama/Llama-2-7b-hf_0    meta-llama/Llama-2-7b-hf_5    meta-llama/Llama-2-7b-chat-hf_0    meta-llama/Llama-2-7b-chat-hf_5\n",
      "-------------------------------  ----------------------------  ----------------------------  ---------------------------------  ---------------------------------\n",
      "meta-llama/Llama-2-7b-hf_0                             1                            74.5641                            67.2813                            66.3199\n",
      "meta-llama/Llama-2-7b-hf_5                            74.5641                        1                                 72.2537                            75.8269\n",
      "meta-llama/Llama-2-7b-chat-hf_0                       67.2813                       72.2537                             1                                 84.7169\n",
      "meta-llama/Llama-2-7b-chat-hf_5                       66.3199                       75.8269                            84.7169                             1\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "cols = [\"meta-llama/Llama-2-7b-hf_0\",\"meta-llama/Llama-2-7b-hf_5\",\"meta-llama/Llama-2-7b-chat-hf_0\",\"meta-llama/Llama-2-7b-chat-hf_5\"]\n",
    "matrix = []\n",
    "for col1 in cols:\n",
    "    for col2 in cols:\n",
    "        if col1==col2:\n",
    "            perc = 1\n",
    "        else:\n",
    "            perc = (pivot_df[[col1,col2]].apply(lambda r: r[col1]==r[col2], axis = 1).sum()/len(pivot_df))*100\n",
    "        matrix.append(perc)\n",
    "matrix = np.array(matrix).reshape([4,4])\n",
    "print(tabulate(matrix, headers=cols,showindex=cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
