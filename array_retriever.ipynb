{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics.utils import hidden_states_collapse\n",
    "from metrics.query import DataFrameQuery\n",
    "from common.tensor_storage import TensorStorage\n",
    "from metrics.utils import  exact_match\n",
    "#from sklearn.feature_selection import mutual_info_regression MISSIN?\n",
    "from dadapy.data import Data\n",
    "\n",
    "from pathlib  import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from common.metadata_db import MetadataDB\n",
    "from common.utils import *\n",
    "from pathlib import Path\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dataframes(db) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate in a dataframe the hidden states of all instances\n",
    "    ----------\n",
    "    hidden_states: pd.DataFrame(num_instances, num_layers, model_dim)\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(\"SELECT * FROM metadata\", db.conn)\n",
    "    df[\"train_instances\"] = df[\"train_instances\"].astype(str)\n",
    "    df.drop(columns=[\"id\"],inplace = True)\n",
    "    #import pdb; pdb.set_trace()\n",
    "    df.drop_duplicates(subset = [\"id_instance\"],inplace = True, ignore_index = True) # why there are duplicates???\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_retrieve(dict_query):\n",
    "    query = DataFrameQuery(dict_query)\n",
    "    hidden_states,logits, hidden_states_df= hidden_states_collapse(metadata_df,query,tensor_storage)\n",
    "    return hidden_states,logits,hidden_states_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructing_labels(label: str, hidden_states_df: pd.DataFrame, hidden_states: np.ndarray) -> np.ndarray:\n",
    "    labels_literals = hidden_states_df[label].unique()\n",
    "    labels_literals.sort()\n",
    "    \n",
    "    map_labels = {class_name: n for n,class_name in enumerate(labels_literals)}\n",
    "    \n",
    "    label_per_row = hidden_states_df[label].reset_index(drop=True)\n",
    "    label_per_row = np.array([map_labels[class_name] for class_name in label_per_row])[:hidden_states.shape[0]]\n",
    "    \n",
    "    return label_per_row, map_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PATH = Path(\"/orfeo/scratch/dssc/zenocosini/mmlu_result\")\n",
    "result_path = Path(_PATH,\"diego\")\n",
    "result_path.mkdir(exist_ok=True,parents=True)\n",
    "metadata_db = MetadataDB(_PATH / \"metadata.db\")\n",
    "metadata_df = set_dataframes(metadata_db)\n",
    "tensor_storage = TensorStorage(Path(_PATH, \"tensor_files\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distances-0.npy   distances-31.npy\tdist_indices-22.npy\n",
      "distances-10.npy  distances-32.npy\tdist_indices-23.npy\n",
      "distances-11.npy  distances-3.npy\tdist_indices-24.npy\n",
      "distances-12.npy  distances-4.npy\tdist_indices-25.npy\n",
      "distances-13.npy  distances-5.npy\tdist_indices-26.npy\n",
      "distances-14.npy  distances-6.npy\tdist_indices-27.npy\n",
      "distances-15.npy  distances-7.npy\tdist_indices-28.npy\n",
      "distances-16.npy  distances-8.npy\tdist_indices-29.npy\n",
      "distances-17.npy  distances-9.npy\tdist_indices-2.npy\n",
      "distances-18.npy  distances-logits.npy\tdist_indices-30.npy\n",
      "distances-19.npy  dist_indices-0.npy\tdist_indices-31.npy\n",
      "distances-1.npy   dist_indices-10.npy\tdist_indices-32.npy\n",
      "distances-20.npy  dist_indices-11.npy\tdist_indices-3.npy\n",
      "distances-21.npy  dist_indices-12.npy\tdist_indices-4.npy\n",
      "distances-22.npy  dist_indices-13.npy\tdist_indices-5.npy\n",
      "distances-23.npy  dist_indices-14.npy\tdist_indices-6.npy\n",
      "distances-24.npy  dist_indices-15.npy\tdist_indices-7.npy\n",
      "distances-25.npy  dist_indices-16.npy\tdist_indices-8.npy\n",
      "distances-26.npy  dist_indices-17.npy\tdist_indices-9.npy\n",
      "distances-27.npy  dist_indices-18.npy\tdist_indices-logits.npy\n",
      "distances-28.npy  dist_indices-19.npy\tletter-map\n",
      "distances-29.npy  dist_indices-1.npy\tsubjects-labels.npy\n",
      "distances-2.npy   dist_indices-20.npy\tsubjects-map\n",
      "distances-30.npy  dist_indices-21.npy\n"
     ]
    }
   ],
   "source": [
    "!ls /orfeo/scratch/dssc/zenocosini/mmlu_result/transposed_dataset/llama-7b-base/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tensor retrieval took: 197.59465193748474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = list(metadata_df[\"dataset\"].unique())\n",
    "dict_query = {\"dataset\":datasets, \n",
    "              \"method\":\"last\",\n",
    "              \"model_name\":\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "              \"train_instances\": shot}\n",
    "hidden_states,logits, hidden_states_df = tensor_retrieve(dict_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p /orfeo/scratch/dssc/zenocosini/mmlu_result/transposed_dataset/llama-7b-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "! ls /orfeo/scratch/dssc/zenocosini/mmlu_result/transposed_dataset/llama-7b-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p /orfeo/scratch/dssc/zenocosini/mmlu_result/transposed_dataset/llama-7b-base/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(_PATH,\"transposed_dataset\",\"llama-7b-chat\",str(shot))\n",
    "path.mkdir(exist_ok=True,parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, map_dict = constructing_labels(\"dataset\",hidden_states_df, hidden_states)\n",
    "np.save(Path(path,\"subjects-labels.pkl\"),labels)\n",
    "with open(Path(path,\"subjects-map\"),\"wb\") as f:\n",
    "    pickle.dump(map_dict,f)\n",
    "labels, map_dict = constructing_labels(\"only_ref_pred\",hidden_states_df, hidden_states)\n",
    "with open(Path(path,\"letter-map.pkl\"),\"wb\") as f:\n",
    "    pickle.dump(map_dict,f)\n",
    "np.save(Path(result_path,\"letter-base\"),labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/dssc/zenocosini/miniconda3/envs/mcqa/lib/python3.11/site-packages/dadapy/_utils/utils.py:152: UserWarning: There are points with neighbours at 0 distance, meaning the dataset probably has identical points.\n",
      "This can cause problems in various routines.\n",
      "We suggest to either perform smearing of distances using\n",
      "remove_zero_dists()\n",
      "or remove identical points using\n",
      "remove_identical_points()).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dict_nn_matrix = {}\n",
    "dict_nn_matrix_l = {}\n",
    "\n",
    "for layer in range(hidden_states.shape[1]):\n",
    "    data = Data(hidden_states[:,layer,:])\n",
    "    data.compute_distances(maxk=150)\n",
    "    \n",
    "    np.save(Path(path,f\"distances-{layer}\"), data.distances)\n",
    "    np.save(Path(path,f\"dist_indices-{layer}\"), data.dist_indices)\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l = Data(logits[:,0,:])\n",
    "data_l.compute_distances(maxk=150)\n",
    "np.save(Path(path,f\"distances-logits\"), data_l.distances)\n",
    "np.save(Path(path,f\"dist_indices-logits\"), data_l.dist_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14015, 151)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14015, 1, 32000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(result_path,\"llama-7b-base-5shot-dist-matrix.pkl\"),\"wb\") as f:\n",
    "    pickle.dump(dict_nn_matrix,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tensor retrieval took: 161.6436107158661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = list(metadata_df[\"dataset\"].unique())\n",
    "dict_query = {\"dataset\":datasets, \n",
    "              \"method\":\"last\",\n",
    "              \"model_name\":\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "              \"train_instances\": 5}\n",
    "hidden_states, hidden_states_df = tensor_retrieve(dict_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(Path(result_path,\"llama-7b-chat-5shot\"), hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, map_labels = constructing_labels(\"dataset\",hidden_states_df, hidden_states)\n",
    "np.save(Path(result_path,\"subjects-chat\"),labels)\n",
    "labels = constructing_labels(\"only_ref_pred\",hidden_states_df, hidden_states)\n",
    "np.save(Path(result_path,\"letter-chat\"),labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_nn_matrix = {}\n",
    "for layer in [6,15,18,29,31]:\n",
    "    data = Data(hidden_states[:,layer,:])\n",
    "    data.compute_distances(maxk=150)\n",
    "    dict_nn_matrix[layer] = (data.distances,data.dist_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(result_path,\"llama-7b-chat-5shot-dist-matrix.pkl\"),\"wb\") as f:\n",
    "    pickle.dump(dict_nn_matrix,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_matches = metadata_df.apply(lambda r: exact_match(r[\"std_pred\"], r[\"letter_gold\"]), axis=1)\n",
    "metadata_df[\"exact_match\"] = exact_matches\n",
    "metadata_df_correct = metadata_df[metadata_df[\"method\"]==\"last\"].copy()\n",
    "\n",
    "#WHATCH OUT: some instance in medicine realated subject are repeated.\n",
    "metadata_df_correct[\"id_instance\"] = metadata_df_correct.apply(lambda r: r[\"id_instance\"][:92]+r[\"id_instance\"][-1], axis=1)\n",
    "metadata_df_correct.drop_duplicates(subset=[\"id_instance\"],inplace = True)\n",
    "metadata_df_correct[\"id_instance\"] = metadata_df_correct.apply(lambda r: r[\"id_instance\"][:64], axis=1)\n",
    "\n",
    "metadata_df_correct.reset_index(inplace=True)\n",
    "metadata_df_correct.drop(columns=[\"index\"],inplace=True)\n",
    "\n",
    "#creating pivot table\n",
    "metadata_df_correct['match_comb'] = metadata_df_correct.apply(lambda row: f\"{row['model_name']}_{row['train_instances']}\", axis=1)\n",
    "pivot_df = metadata_df_correct.pivot(index='id_instance', columns='match_comb', values='exact_match')\n",
    "pivot_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_instance', 'meta-llama/Llama-2-7b-chat-hf_0',\n",
       "       'meta-llama/Llama-2-7b-chat-hf_2', 'meta-llama/Llama-2-7b-chat-hf_5',\n",
       "       'meta-llama/Llama-2-7b-hf_0', 'meta-llama/Llama-2-7b-hf_2',\n",
       "       'meta-llama/Llama-2-7b-hf_5'],\n",
       "      dtype='object', name='match_comb')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   meta-llama/Llama-2-7b-hf_0    meta-llama/Llama-2-7b-hf_5    meta-llama/Llama-2-7b-chat-hf_0    meta-llama/Llama-2-7b-chat-hf_5\n",
      "-------------------------------  ----------------------------  ----------------------------  ---------------------------------  ---------------------------------\n",
      "meta-llama/Llama-2-7b-hf_0                             1                            74.5641                            67.2813                            66.3199\n",
      "meta-llama/Llama-2-7b-hf_5                            74.5641                        1                                 72.2537                            75.8269\n",
      "meta-llama/Llama-2-7b-chat-hf_0                       67.2813                       72.2537                             1                                 84.7169\n",
      "meta-llama/Llama-2-7b-chat-hf_5                       66.3199                       75.8269                            84.7169                             1\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "cols = [\"meta-llama/Llama-2-7b-hf_0\",\"meta-llama/Llama-2-7b-hf_5\",\"meta-llama/Llama-2-7b-chat-hf_0\",\"meta-llama/Llama-2-7b-chat-hf_5\"]\n",
    "matrix = []\n",
    "for col1 in cols:\n",
    "    for col2 in cols:\n",
    "        if col1==col2:\n",
    "            perc = 1\n",
    "        else:\n",
    "            perc = (pivot_df[[col1,col2]].apply(lambda r: r[col1]==r[col2], axis = 1).sum()/len(pivot_df))*100\n",
    "        matrix.append(perc)\n",
    "matrix = np.array(matrix).reshape([4,4])\n",
    "print(tabulate(matrix, headers=cols,showindex=cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
