{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics.utils import hidden_states_collapse\n",
    "from metrics.query import DataFrameQuery\n",
    "from common.tensor_storage import TensorStorage\n",
    "from common.metadata_db import MetadataDB\n",
    "from common.utils import *\n",
    "from metrics.utils import  exact_match, angular_distance\n",
    "\n",
    "#from sklearn.feature_selection import mutual_info_regression MISSIN?\n",
    "from dadapy.data import Data\n",
    "\n",
    "from pathlib  import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dataframes(db) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate in a dataframe the hidden states of all instances\n",
    "    ----------\n",
    "    hidden_states: pd.DataFrame(num_instances, num_layers, model_dim)\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(\"SELECT * FROM metadata\", db.conn)\n",
    "    df[\"train_instances\"] = df[\"train_instances\"].astype(str)\n",
    "    df.drop(columns=[\"id\"],inplace = True)\n",
    "    #import pdb; pdb.set_trace()\n",
    "    df.drop_duplicates(subset = [\"id_instance\"],inplace = True, ignore_index = True) # why there are duplicates???\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_retrieve(dict_query):\n",
    "    query = DataFrameQuery(dict_query)\n",
    "    hidden_states,logits, hidden_states_df= hidden_states_collapse(df_hiddenstates=metadata_df,query=query,tensor_storage=tensor_storage)\n",
    "    return hidden_states,logits,hidden_states_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructing_labels(label: str, hidden_states_df: pd.DataFrame, hidden_states: np.ndarray) -> np.ndarray:\n",
    "    labels_literals = hidden_states_df[label].unique()\n",
    "    labels_literals.sort()\n",
    "    \n",
    "    map_labels = {class_name: n for n,class_name in enumerate(labels_literals)}\n",
    "    \n",
    "    label_per_row = hidden_states_df[label].reset_index(drop=True)\n",
    "    label_per_row = np.array([map_labels[class_name] for class_name in label_per_row])[:hidden_states.shape[0]]\n",
    "    \n",
    "    return label_per_row, map_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PATH = Path(\"/orfeo/scratch/dssc/zenocosini/mmlu_result/\")\n",
    "result_path = Path(_PATH,\"log_reg\")\n",
    "result_path.mkdir(exist_ok=True,parents=True)\n",
    "metadata_db = MetadataDB(_PATH / \"metadata.db\")\n",
    "metadata_df = set_dataframes(metadata_db)\n",
    "tensor_storage = TensorStorage(Path(_PATH, \"tensor_files\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_query = { \"method\":\"last\",\n",
    "              \"model_name\":\"meta-llama/Llama-2-7b-hf\",\n",
    "              \"train_instances\": 0}\n",
    "query = DataFrameQuery(dict_query)\n",
    "df_hiddenstates = query.apply_query(metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test sets for each subject\n",
    "train_frames = []\n",
    "test_frames = []\n",
    "\n",
    "for subject in df_hiddenstates['dataset'].unique():\n",
    "    subject_data = df_hiddenstates[df_hiddenstates['dataset'] == subject]\n",
    "    train, test = train_test_split(subject_data, test_size=0.2, random_state=42)\n",
    "    train_frames.append(train)\n",
    "    test_frames.append(test)\n",
    "\n",
    "train_df = pd.concat(train_frames)\n",
    "test_df = pd.concat(test_frames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tensor retrieval took: 144.9542293548584\n",
      "\n",
      " Tensor retrieval took: 1.6496326923370361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, _, df_train = hidden_states_collapse(df_hiddenstates=train_df,tensor_storage=tensor_storage)\n",
    "X_test, _, df_test = hidden_states_collapse(df_hiddenstates=test_df,tensor_storage=tensor_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'A', ..., 'B', '', ''], dtype='<U10')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_df['std_pred']\n",
    "np.asarray(y_train.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tensor retrieval took: 6.083222389221191\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/dssc/zenocosini/miniconda3/envs/mcqa/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tensor retrieval took: 2.1171014308929443\n",
      "\n",
      "The accuracy of the logistic regression model is: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Preparing the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)  # Increased max_iter to ensure convergence\n",
    "\n",
    "# Training the model\n",
    "X_train, _, train_df = hidden_states_collapse(df_hiddenstates=train_df,tensor_storage=tensor_storage)\n",
    "y_train = np.asarray(train_df['std_pred'].tolist())\n",
    "model.fit(X_train[:,-1,:], y_train)\n",
    "\n",
    "# Testing the model\n",
    "X_test, _, test_df = hidden_states_collapse(df_hiddenstates=test_df,tensor_storage=tensor_storage)\n",
    "y_test = np.asarray(test_df['std_pred'].tolist())\n",
    "predictions = model.predict(X_test[:,-1,:])\n",
    "\n",
    "# Calculating the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'The accuracy of the logistic regression model is: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/orfeo/scratch/dssc/zenocosini/mmlu_result/log_reg/test_model.joblib']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, Path(result_path, \"test_model.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/orfeo/scratch/dssc/zenocosini/mmlu_result/log_reg/test\n"
     ]
    }
   ],
   "source": [
    "!ls /orfeo/scratch/dssc/zenocosini/mmlu_result/log_reg/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tensor retrieval took: 9.455770254135132\n",
      "\n",
      " Tensor retrieval took: 1.6556823253631592\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m weights \u001b[38;5;241m=\u001b[39m compute_class_weight(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, classes\u001b[38;5;241m=\u001b[39mclasses, y\u001b[38;5;241m=\u001b[39mtrain_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monly_ref_pred\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     13\u001b[0m class_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(classes, weights))\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Preparing the logistic regression model\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mLogisticRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Increased max_iter to ensure convergence\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Training the model\u001b[39;49;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Train set\n",
    "X_train, _, train_df = hidden_states_collapse(df_hiddenstates=train_df,tensor_storage=tensor_storage)\n",
    "y_train = np.asarray(train_df['only_ref_pred'].tolist())\n",
    "# Test set \n",
    "X_test, _, test_df = hidden_states_collapse(df_hiddenstates=test_df,tensor_storage=tensor_storage)\n",
    "y_test = np.asarray(test_df['only_ref_pred'].tolist())\n",
    "\n",
    "models = []\n",
    "performance_per_layer = []\n",
    "\n",
    "classes = train_df['only_ref_pred'].unique()\n",
    "weights = compute_class_weight('balanced', classes=classes, y=train_df['only_ref_pred'])\n",
    "class_weight = dict(zip(classes, weights))\n",
    "\n",
    "for layer in range(X_train.shape[1]):\n",
    "    # Preparing the logistic regression model\n",
    "    model = LogisticRegression(max_iter=1000, class_weight=class_weight)  # Increased max_iter to ensure convergence\n",
    "    \n",
    "    # Training the model\n",
    "    model.fit(X_train[:,layer,:], y_train)\n",
    "    \n",
    "    # Testing the model\n",
    "    predictions = model.predict(X_test[:,layer,:])\n",
    "    \n",
    "    # Calculating the accuracy of the model\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "    joblib.dump(model, Path(result_path, f\"model_layer{layer}.joblib\"))\n",
    "    print(f'The accuracy of the logistic regression model at layer {layer} is: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/alexserra98/helm-suite/MCQA_Benchmark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hiddenstates = retrieve_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_instance</th>\n",
       "      <th>dataset</th>\n",
       "      <th>train_instances</th>\n",
       "      <th>model_name</th>\n",
       "      <th>loss</th>\n",
       "      <th>std_pred</th>\n",
       "      <th>only_ref_pred</th>\n",
       "      <th>letter_gold</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b00426998cd78bacf9cda0a3ee982b9a701a1aaf27f1bc...</td>\n",
       "      <td>mmlu:abstract_algebra</td>\n",
       "      <td>0</td>\n",
       "      <td>meta-llama/Llama-2-7b-hf</td>\n",
       "      <td>1.782583</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3923170ff65deeb8fd811b5a6a8b42158de643a9624f34...</td>\n",
       "      <td>mmlu:abstract_algebra</td>\n",
       "      <td>0</td>\n",
       "      <td>meta-llama/Llama-2-7b-hf</td>\n",
       "      <td>1.939811</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c988e801c0e8c5817e97ec09e0ff7b24fc6baffa7ad52c...</td>\n",
       "      <td>mmlu:abstract_algebra</td>\n",
       "      <td>0</td>\n",
       "      <td>meta-llama/Llama-2-7b-hf</td>\n",
       "      <td>2.436764</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5b77183243dc1b981af1e0bc0db89dac081dfc8091fbf8...</td>\n",
       "      <td>mmlu:abstract_algebra</td>\n",
       "      <td>0</td>\n",
       "      <td>meta-llama/Llama-2-7b-hf</td>\n",
       "      <td>2.262146</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3d206776b665f4a50a422de4c4a2a87a4bccfbccbd1cf0...</td>\n",
       "      <td>mmlu:abstract_algebra</td>\n",
       "      <td>0</td>\n",
       "      <td>meta-llama/Llama-2-7b-hf</td>\n",
       "      <td>1.921660</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83396</th>\n",
       "      <td>b6f7a59850be96f1617452cabfd87d56cba63864642ee8...</td>\n",
       "      <td>mmlu:world_religions</td>\n",
       "      <td>0</td>\n",
       "      <td>meta-llama/Llama-2-7b-hf</td>\n",
       "      <td>1.422237</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83398</th>\n",
       "      <td>10651bc943b4de4119acb9715064f2c805b5c1fdcea384...</td>\n",
       "      <td>mmlu:world_religions</td>\n",
       "      <td>0</td>\n",
       "      <td>meta-llama/Llama-2-7b-hf</td>\n",
       "      <td>2.855837</td>\n",
       "      <td></td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83400</th>\n",
       "      <td>e4489670ba6964318f9ab60db2f087a0c355ed2825d0a3...</td>\n",
       "      <td>mmlu:world_religions</td>\n",
       "      <td>0</td>\n",
       "      <td>meta-llama/Llama-2-7b-hf</td>\n",
       "      <td>2.688995</td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83402</th>\n",
       "      <td>5dd4ef6f9a03382ccffcee09203d5a97f8f2d48c21c523...</td>\n",
       "      <td>mmlu:world_religions</td>\n",
       "      <td>0</td>\n",
       "      <td>meta-llama/Llama-2-7b-hf</td>\n",
       "      <td>1.356830</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83404</th>\n",
       "      <td>a798a6822de201343664dfc20fe9e390370015686a8ae2...</td>\n",
       "      <td>mmlu:world_religions</td>\n",
       "      <td>0</td>\n",
       "      <td>meta-llama/Llama-2-7b-hf</td>\n",
       "      <td>2.347366</td>\n",
       "      <td></td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14015 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             id_instance  \\\n",
       "0      b00426998cd78bacf9cda0a3ee982b9a701a1aaf27f1bc...   \n",
       "2      3923170ff65deeb8fd811b5a6a8b42158de643a9624f34...   \n",
       "4      c988e801c0e8c5817e97ec09e0ff7b24fc6baffa7ad52c...   \n",
       "6      5b77183243dc1b981af1e0bc0db89dac081dfc8091fbf8...   \n",
       "8      3d206776b665f4a50a422de4c4a2a87a4bccfbccbd1cf0...   \n",
       "...                                                  ...   \n",
       "83396  b6f7a59850be96f1617452cabfd87d56cba63864642ee8...   \n",
       "83398  10651bc943b4de4119acb9715064f2c805b5c1fdcea384...   \n",
       "83400  e4489670ba6964318f9ab60db2f087a0c355ed2825d0a3...   \n",
       "83402  5dd4ef6f9a03382ccffcee09203d5a97f8f2d48c21c523...   \n",
       "83404  a798a6822de201343664dfc20fe9e390370015686a8ae2...   \n",
       "\n",
       "                     dataset train_instances                model_name  \\\n",
       "0      mmlu:abstract_algebra               0  meta-llama/Llama-2-7b-hf   \n",
       "2      mmlu:abstract_algebra               0  meta-llama/Llama-2-7b-hf   \n",
       "4      mmlu:abstract_algebra               0  meta-llama/Llama-2-7b-hf   \n",
       "6      mmlu:abstract_algebra               0  meta-llama/Llama-2-7b-hf   \n",
       "8      mmlu:abstract_algebra               0  meta-llama/Llama-2-7b-hf   \n",
       "...                      ...             ...                       ...   \n",
       "83396   mmlu:world_religions               0  meta-llama/Llama-2-7b-hf   \n",
       "83398   mmlu:world_religions               0  meta-llama/Llama-2-7b-hf   \n",
       "83400   mmlu:world_religions               0  meta-llama/Llama-2-7b-hf   \n",
       "83402   mmlu:world_religions               0  meta-llama/Llama-2-7b-hf   \n",
       "83404   mmlu:world_religions               0  meta-llama/Llama-2-7b-hf   \n",
       "\n",
       "           loss std_pred only_ref_pred letter_gold method  \n",
       "0      1.782583        B             B           B   last  \n",
       "2      1.939811        A             A           C   last  \n",
       "4      2.436764        B             B           D   last  \n",
       "6      2.262146        A             A           B   last  \n",
       "8      1.921660        D             D           B   last  \n",
       "...         ...      ...           ...         ...    ...  \n",
       "83396  1.422237        A             A           A   last  \n",
       "83398  2.855837                      A           C   last  \n",
       "83400  2.688995                      B           B   last  \n",
       "83402  1.356830        A             A           B   last  \n",
       "83404  2.347366                      A           A   last  \n",
       "\n",
       "[14015 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hiddenstates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_hiddenstates,stratify=df_hiddenstates[\"dataset\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train, test in skf.split(df_hiddenstates, df_hiddenstates[\"dataset\"]):\n",
    "    X_train, y_train = df_hiddenstates.iloc[train], df_hiddenstates.iloc[train][\"std_pred\"]\n",
    "    X_test, y_test = df_hiddenstates.iloc[test], df_hiddenstates.iloc[test][\"std_pred\"]\n",
    "    \n",
    "    model = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f'The accuracy of the logistic regression model is: {accuracy:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
