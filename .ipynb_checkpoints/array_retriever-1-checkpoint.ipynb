{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/dssc/zenocosini/miniconda3/envs/mcqa/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from metrics.utils import hidden_states_collapse\n",
    "from metrics.query import DataFrameQuery\n",
    "from common.tensor_storage import TensorStorage\n",
    "from common.metadata_db import MetadataDB\n",
    "from metrics.utils import  exact_match, angular_distance\n",
    "\n",
    "#from sklearn.feature_selection import mutual_info_regression MISSIN?\n",
    "from dadapy.data import Data\n",
    "\n",
    "from pathlib  import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "from common.metadata_db import MetadataDB\n",
    "from common.utils import *\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dataframes(db) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate in a dataframe the hidden states of all instances\n",
    "    ----------\n",
    "    hidden_states: pd.DataFrame(num_instances, num_layers, model_dim)\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(\"SELECT * FROM metadata\", db.conn)\n",
    "    df[\"train_instances\"] = df[\"train_instances\"].astype(str)\n",
    "    df.drop(columns=[\"id\"],inplace = True)\n",
    "    #import pdb; pdb.set_trace()\n",
    "    df.drop_duplicates(subset = [\"id_instance\"],inplace = True, ignore_index = True) # why there are duplicates???\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_retrieve(dict_query):\n",
    "    query = DataFrameQuery(dict_query)\n",
    "    hidden_states,logits, hidden_states_df= hidden_states_collapse(metadata_df,query,tensor_storage)\n",
    "    return hidden_states,logits,hidden_states_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructing_labels(label: str, hidden_states_df: pd.DataFrame, hidden_states: np.ndarray) -> np.ndarray:\n",
    "    labels_literals = hidden_states_df[label].unique()\n",
    "    labels_literals.sort()\n",
    "    \n",
    "    map_labels = {class_name: n for n,class_name in enumerate(labels_literals)}\n",
    "    \n",
    "    label_per_row = hidden_states_df[label].reset_index(drop=True)\n",
    "    label_per_row = np.array([map_labels[class_name] for class_name in label_per_row])[:hidden_states.shape[0]]\n",
    "    \n",
    "    return label_per_row, map_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PATH = Path(\"/orfeo/scratch/dssc/zenocosini/commonsenseqa_letter_result/\")\n",
    "result_path = Path(_PATH,\"diego\")\n",
    "result_path.mkdir(exist_ok=True,parents=True)\n",
    "metadata_db = MetadataDB(_PATH / \"metadata.db\")\n",
    "metadata_df = set_dataframes(metadata_db)\n",
    "tensor_storage = TensorStorage(Path(_PATH, \"tensor_files\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distances-0.npy   distances-31.npy\tdist_indices-22.npy\n",
      "distances-10.npy  distances-32.npy\tdist_indices-23.npy\n",
      "distances-11.npy  distances-3.npy\tdist_indices-24.npy\n",
      "distances-12.npy  distances-4.npy\tdist_indices-25.npy\n",
      "distances-13.npy  distances-5.npy\tdist_indices-26.npy\n",
      "distances-14.npy  distances-6.npy\tdist_indices-27.npy\n",
      "distances-15.npy  distances-7.npy\tdist_indices-28.npy\n",
      "distances-16.npy  distances-8.npy\tdist_indices-29.npy\n",
      "distances-17.npy  distances-9.npy\tdist_indices-2.npy\n",
      "distances-18.npy  distances-logits.npy\tdist_indices-30.npy\n",
      "distances-19.npy  dist_indices-0.npy\tdist_indices-31.npy\n",
      "distances-1.npy   dist_indices-10.npy\tdist_indices-32.npy\n",
      "distances-20.npy  dist_indices-11.npy\tdist_indices-3.npy\n",
      "distances-21.npy  dist_indices-12.npy\tdist_indices-4.npy\n",
      "distances-22.npy  dist_indices-13.npy\tdist_indices-5.npy\n",
      "distances-23.npy  dist_indices-14.npy\tdist_indices-6.npy\n",
      "distances-24.npy  dist_indices-15.npy\tdist_indices-7.npy\n",
      "distances-25.npy  dist_indices-16.npy\tdist_indices-8.npy\n",
      "distances-26.npy  dist_indices-17.npy\tdist_indices-9.npy\n",
      "distances-27.npy  dist_indices-18.npy\tdist_indices-logits.npy\n",
      "distances-28.npy  dist_indices-19.npy\tletter-map\n",
      "distances-29.npy  dist_indices-1.npy\tsubjects-labels.npy\n",
      "distances-2.npy   dist_indices-20.npy\tsubjects-map\n",
      "distances-30.npy  dist_indices-21.npy\n"
     ]
    }
   ],
   "source": [
    "!ls /orfeo/scratch/dssc/zenocosini/mmlu_result/transposed_dataset/llama-7b-base/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tensor retrieval took: 197.59465193748474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = list(metadata_df[\"dataset\"].unique())\n",
    "dict_query = {\"dataset\":datasets, \n",
    "              \"method\":\"last\",\n",
    "              \"model_name\":\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "              \"train_instances\": shot}\n",
    "hidden_states,logits, hidden_states_df = tensor_retrieve(dict_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1221, 1, 32000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p /orfeo/scratch/dssc/zenocosini/mmlu_result/transposed_dataset/llama-7b-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "! ls /orfeo/scratch/dssc/zenocosini/mmlu_result/transposed_dataset/llama-7b-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p /orfeo/scratch/dssc/zenocosini/mmlu_result/transposed_dataset/llama-7b-base/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(_PATH,\"transposed_dataset\",\"llama-7b-chat\",str(shot))\n",
    "path.mkdir(exist_ok=True,parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, map_dict = constructing_labels(\"dataset\",hidden_states_df, hidden_states)\n",
    "np.save(Path(path,\"subjects-labels.pkl\"),labels)\n",
    "with open(Path(path,\"subjects-map\"),\"wb\") as f:\n",
    "    pickle.dump(map_dict,f)\n",
    "labels, map_dict = constructing_labels(\"only_ref_pred\",hidden_states_df, hidden_states)\n",
    "with open(Path(path,\"letter-map.pkl\"),\"wb\") as f:\n",
    "    pickle.dump(map_dict,f)\n",
    "np.save(Path(result_path,\"letter-base\"),labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/dssc/zenocosini/miniconda3/envs/mcqa/lib/python3.11/site-packages/dadapy/_utils/utils.py:152: UserWarning: There are points with neighbours at 0 distance, meaning the dataset probably has identical points.\n",
      "This can cause problems in various routines.\n",
      "We suggest to either perform smearing of distances using\n",
      "remove_zero_dists()\n",
      "or remove identical points using\n",
      "remove_identical_points()).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dict_nn_matrix = {}\n",
    "dict_nn_matrix_l = {}\n",
    "\n",
    "for layer in range(hidden_states.shape[1]):\n",
    "    data = Data(hidden_states[:,layer,:])\n",
    "    data.compute_distances(maxk=150)\n",
    "    \n",
    "    np.save(Path(path,f\"distances-{layer}\"), data.distances)\n",
    "    np.save(Path(path,f\"dist_indices-{layer}\"), data.dist_indices)\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l = Data(logits[:,0,:])\n",
    "data_l.compute_distances(maxk=150)\n",
    "np.save(Path(path,f\"distances-logits\"), data_l.distances)\n",
    "np.save(Path(path,f\"dist_indices-logits\"), data_l.dist_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14015, 151)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14015, 1, 32000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(result_path,\"llama-7b-base-5shot-dist-matrix.pkl\"),\"wb\") as f:\n",
    "    pickle.dump(dict_nn_matrix,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tensor retrieval took: 161.6436107158661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = list(metadata_df[\"dataset\"].unique())\n",
    "dict_query = {\"dataset\":datasets, \n",
    "              \"method\":\"last\",\n",
    "              \"model_name\":\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "              \"train_instances\": 5}\n",
    "hidden_states, hidden_states_df = tensor_retrieve(dict_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(Path(result_path,\"llama-7b-chat-5shot\"), hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, map_labels = constructing_labels(\"dataset\",hidden_states_df, hidden_states)\n",
    "np.save(Path(result_path,\"subjects-chat\"),labels)\n",
    "labels = constructing_labels(\"only_ref_pred\",hidden_states_df, hidden_states)\n",
    "np.save(Path(result_path,\"letter-chat\"),labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_nn_matrix = {}\n",
    "for layer in [6,15,18,29,31]:\n",
    "    data = Data(hidden_states[:,layer,:])\n",
    "    data.compute_distances(maxk=150)\n",
    "    dict_nn_matrix[layer] = (data.distances,data.dist_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(result_path,\"llama-7b-chat-5shot-dist-matrix.pkl\"),\"wb\") as f:\n",
    "    pickle.dump(dict_nn_matrix,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap Correct Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_matches = metadata_df.apply(lambda r: exact_match(r[\"std_pred\"], r[\"letter_gold\"]), axis=1)\n",
    "metadata_df[\"exact_match\"] = exact_matches\n",
    "metadata_df_correct = metadata_df[metadata_df[\"method\"]==\"last\"].copy()\n",
    "\n",
    "#WHATCH OUT: some instance in medicine realated subject are repeated.\n",
    "metadata_df_correct[\"id_instance\"] = metadata_df_correct.apply(lambda r: r[\"id_instance\"][:92]+r[\"id_instance\"][-1], axis=1)\n",
    "metadata_df_correct.drop_duplicates(subset=[\"id_instance\"],inplace = True)\n",
    "metadata_df_correct[\"id_instance\"] = metadata_df_correct.apply(lambda r: r[\"id_instance\"][:64], axis=1)\n",
    "\n",
    "metadata_df_correct.reset_index(inplace=True)\n",
    "metadata_df_correct.drop(columns=[\"index\"],inplace=True)\n",
    "\n",
    "#creating pivot table\n",
    "metadata_df_correct['match_comb'] = metadata_df_correct.apply(lambda row: f\"{row['model_name']}_{row['train_instances']}\", axis=1)\n",
    "pivot_df = metadata_df_correct.pivot( index='id_instance',columns='match_comb', values='exact_match')\n",
    "pivot_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              meta-llama/Llama-2-7b-hf\n",
       "2              meta-llama/Llama-2-7b-hf\n",
       "4              meta-llama/Llama-2-7b-hf\n",
       "6              meta-llama/Llama-2-7b-hf\n",
       "8              meta-llama/Llama-2-7b-hf\n",
       "                      ...              \n",
       "168170    meta-llama/Llama-2-7b-chat-hf\n",
       "168172    meta-llama/Llama-2-7b-chat-hf\n",
       "168174    meta-llama/Llama-2-7b-chat-hf\n",
       "168176    meta-llama/Llama-2-7b-chat-hf\n",
       "168178    meta-llama/Llama-2-7b-chat-hf\n",
       "Name: model_name, Length: 83622, dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df_correct[\"model_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   meta-llama/Llama-2-7b-hf_0    meta-llama/Llama-2-7b-hf_5    meta-llama/Llama-2-7b-chat-hf_0    meta-llama/Llama-2-7b-chat-hf_5\n",
      "-------------------------------  ----------------------------  ----------------------------  ---------------------------------  ---------------------------------\n",
      "meta-llama/Llama-2-7b-hf_0                                1                            36.2                               31.8                               32.4\n",
      "meta-llama/Llama-2-7b-hf_5                               36.2                           1                                 44.6                               47.2\n",
      "meta-llama/Llama-2-7b-chat-hf_0                          31.8                          44.6                                1                                 54.8\n",
      "meta-llama/Llama-2-7b-chat-hf_5                          32.4                          47.2                               54.8                                1\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "cols = [\"meta-llama/Llama-2-7b-hf_0\",\"meta-llama/Llama-2-7b-hf_5\",\"meta-llama/Llama-2-7b-chat-hf_0\",\"meta-llama/Llama-2-7b-chat-hf_5\"]\n",
    "matrix = []\n",
    "for col1 in cols:\n",
    "    for col2 in cols:\n",
    "        if col1==col2:\n",
    "            perc = 1\n",
    "        else:\n",
    "            perc = (pivot_df[[col1,col2]].apply(lambda r: r[col1]==r[col2] and r[col1]==True, axis = 1).sum()/len(pivot_df))*100\n",
    "        matrix.append(perc)\n",
    "matrix = np.array(matrix).reshape([4,4])\n",
    "print(tabulate(matrix, headers=cols,showindex=cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1221, 32000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_i.squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PATH = Path(\"/orfeo/scratch/dssc/zenocosini/mmlu_result/\")\n",
    "result_path = Path(_PATH,\"diego\")\n",
    "result_path.mkdir(exist_ok=True,parents=True)\n",
    "metadata_db = MetadataDB(_PATH / \"metadata.db\")\n",
    "metadata_df = set_dataframes(metadata_db)\n",
    "tensor_storage = TensorStorage(Path(_PATH, \"tensor_files\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PATH = Path(\"/orfeo/scratch/dssc/zenocosini/commonsenseqa_letter_result/\")\n",
    "result_path = Path(_PATH,\"diego\")\n",
    "result_path.mkdir(exist_ok=True,parents=True)\n",
    "metadata_db_cs = MetadataDB(_PATH / \"metadata.db\")\n",
    "metadata_df_cs = set_dataframes(metadata_db)\n",
    "tensor_storage_cs = TensorStorage(Path(_PATH, \"tensor_files\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PATH = Path(\"/orfeo/scratch/dssc/zenocosini/openbookqa_result/\")\n",
    "result_path = Path(_PATH,\"diego\")\n",
    "result_path.mkdir(exist_ok=True,parents=True)\n",
    "metadata_db_ob = MetadataDB(_PATH / \"metadata.db\")\n",
    "metadata_df_ob = set_dataframes(metadata_db)\n",
    "tensor_storage_ob = TensorStorage(Path(_PATH, \"tensor_files\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b\")\n",
    "index_letter = [tokenizer.encode(letter)[1] for letter in [\"A\",\"B\",\"C\",\"D\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angular_distance(mat):\n",
    "    \"\"\"\n",
    "    Computes distance based on angles between vectors, over the rows of the matrix\n",
    "    \"\"\"\n",
    "    dot_product = mat @ mat.T\n",
    "    norm_vector = np.linalg.norm(mat, axis=1)\n",
    "    stacked_vector = np.tile(norm_vector, (mat.shape[0], 1))\n",
    "    norm_product = stacked_vector.T*stacked_vector\n",
    "\n",
    "    cosine_similarity = dot_product / norm_product\n",
    "    cosine_similarity = np.clip(cosine_similarity, -1, 1)\n",
    "    distances = np.arccos(cosine_similarity) / np.pi\n",
    "    #distances.sort(axis=1)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_computer(logits_1,logits_2, cosine = \"False\", k=30):\n",
    "    if cosine:\n",
    "        distances_1 = angular_distance(logits_1)\n",
    "        distances_2 = angular_distance(logits_2)\n",
    "        data = Data(coordinates=logits_1, distances=distances_1, maxk=1000)\n",
    "        overlap = data.return_data_overlap(coordinates=logits_2, distances=distances_2, k=k)\n",
    "    else:\n",
    "        data = Data(logits_1,maxk=100)\n",
    "        overlap = data.return_data_overlap(logits_2, k=k)\n",
    "    print(f'{overlap=}')\n",
    "    return overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_values = np.exp(x)# - np.max(x, axis=-1, keepdims=True))\n",
    "    probabilities = exp_values / np.sum(exp_values, axis=-1, keepdims=True)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(dict_query_i, dict_query_j):\n",
    "\n",
    "    hidden_states_i, logits_i, df_i = tensor_retrieve(dict_query_i)\n",
    "    hidden_states_j,logits_j, df_j = tensor_retrieve(dict_query_j)\n",
    "    df_i[\"exact_match\"] = df_i.apply(lambda r: exact_match(r[\"std_pred\"], r[\"letter_gold\"]), axis=1)\n",
    "    df_j[\"exact_match\"] = df_j.apply(lambda r: exact_match(r[\"std_pred\"], r[\"letter_gold\"]), axis=1)\n",
    "    \n",
    "    df_i.reset_index(inplace=True)\n",
    "    df_j.reset_index(inplace=True)\n",
    "    df_i.drop(\"index\", axis=1,inplace=True)\n",
    "    df_j.drop(\"index\", axis=1,inplace=True)\n",
    "    # find the index of rows that have \"exact_match\" True in both df_i and df_j\n",
    "    indices_i = df_i[df_i[\"exact_match\"] == True].index\n",
    "    indices_j = df_j[df_j[\"exact_match\"] == True].index\n",
    "    \n",
    "    # find the intersection of the two sets of indices\n",
    "    indices = indices_i.intersection(indices_j)\n",
    "    logits_i = logits_i.squeeze(1)\n",
    "    logits_j = logits_j.squeeze(1)\n",
    "    logits_i = logits_i[indices]\n",
    "    logits_j = logits_j[indices]\n",
    "    logits_i_only_letter = logits_i[:,index_letter]\n",
    "    logits_j_only_letter = logits_j[:,index_letter]\n",
    "    return (logits_i, logits_j), (logits_i_only_letter, logits_j_only_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_overlap(dict_query_i,dict_query_j):\n",
    "    standard_logits, letter_logits = setup(dict_query_i,dict_query_j)\n",
    "    dict_result = {}\n",
    "    #standard\n",
    "    print(\"Computing standard\")\n",
    "    logits_i,logits_j = standard_logits\n",
    "    dict_result[\"std\"] =  overlap_computer(logits_i,logits_j, cosine=False, k=500)\n",
    "    #softmax standard\n",
    "    print(\"Computing softmax standard\")\n",
    "    softmx_i = softmax(logits_i)\n",
    "    softmx_j = softmax(logits_j)\n",
    "    dict_result[\"softmax-std\"] =  overlap_computer(softmx_i,softmx_j, cosine=False, k=500)\n",
    "    #softmax cosine\n",
    "    print(\"Computing softmax cosine\")\n",
    "    dict_result[\"softmax-cosine\"] =  overlap_computer(softmx_i,softmx_j, cosine=True, k=500)\n",
    "    #softmx_norm\n",
    "    print(\"Computing softmax norm\")\n",
    "    logits_i_norm = logits_i/np.linalg.norm(logits_i,axis=1, keepdims=True)  \n",
    "    logits_j_norm = logits_j/np.linalg.norm(logits_j,axis=1, keepdims=True)\n",
    "    softmx_i = softmax(logits_i_norm)\n",
    "    softmx_j = softmax(logits_j_norm)\n",
    "    dict_result[\"softmax-norm\"] =  overlap_computer(softmx_i,softmx_j, cosine=False, k=500)\n",
    "    return dict_result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tensor retrieval took: 195.97466778755188\n",
      "\n",
      " Tensor retrieval took: 161.93579030036926\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2261942/4181773619.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_i[\"exact_match\"] = df_i.apply(lambda r: exact_match(r[\"std_pred\"], r[\"letter_gold\"]), axis=1)\n",
      "/tmp/ipykernel_2261942/4181773619.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_j[\"exact_match\"] = df_j.apply(lambda r: exact_match(r[\"std_pred\"], r[\"letter_gold\"]), axis=1)\n",
      "/tmp/ipykernel_2261942/4181773619.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_i.drop(\"index\", axis=1,inplace=True)\n",
      "/tmp/ipykernel_2261942/4181773619.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_j.drop(\"index\", axis=1,inplace=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[217], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m dict_query_i \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      2\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-2-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_instances\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m}\n\u001b[1;32m      4\u001b[0m dict_query_j \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-2-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_instances\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m}\n\u001b[0;32m----> 7\u001b[0m result_1 \u001b[38;5;241m=\u001b[39m \u001b[43mlogits_overlap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdict_query_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_query_j\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[216], line 2\u001b[0m, in \u001b[0;36mlogits_overlap\u001b[0;34m(dict_query_i, dict_query_j)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogits_overlap\u001b[39m(dict_query_i,dict_query_j):\n\u001b[0;32m----> 2\u001b[0m     standard_logits, letter_logits \u001b[38;5;241m=\u001b[39m setup(dict_query_i,dict_query_j)\n\u001b[1;32m      3\u001b[0m     dict_result \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#standard\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "dict_query_i = {\"method\":\"last\",\n",
    "              \"model_name\":\"meta-llama/Llama-2-7b-hf\",\n",
    "              \"train_instances\": 5}\n",
    "dict_query_j = {\"method\":\"last\",\n",
    "              \"model_name\":\"meta-llama/Llama-2-7b-hf\",\n",
    "              \"train_instances\": 0}\n",
    "result_1 = logits_overlap(dict_query_i, dict_query_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_query_i = {\"method\":\"last\",\n",
    "              \"model_name\":\"meta-llama/Llama-2-7b-hf\",\n",
    "              \"train_instances\": 5}\n",
    "dict_query_j = {\"method\":\"last\",\n",
    "              \"model_name\":\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "              \"train_instances\": 0}\n",
    "result_2 = logits_overlap(dict_query_i, dict_query_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_query_i = {\"method\":\"last\",\n",
    "              \"model_name\":\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "              \"train_instances\": 5}\n",
    "dict_query_j = {\"method\":\"last\",\n",
    "              \"model_name\":\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "              \"train_instances\": 0}\n",
    "result_3 = logits_overlap(dict_query_i, dict_query_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_query_i = {\"method\":\"last\",\n",
    "              \"model_name\":\"meta-llama/Llama-2-7b-hf\",\n",
    "              \"train_instances\": 1}\n",
    "dict_query_j = {\"method\":\"last\",\n",
    "              \"model_name\":\"meta-llama/Llama-2-7b-hf\",\n",
    "              \"train_instances\": 2}\n",
    "result_1 = logits_overlap(dict_query_i, dict_query_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmx_i = softmax(logits_i)\n",
    "softmx_j = softmax(logits_j)\n",
    "softmx_i_norm = softmax(logits_i_norm)\n",
    "softmx_j_norm = softmax(logits_j_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap=0.5096862147753237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5096862147753237"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_computer(softmx_i,softmx_j, cosine=True, k=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap=0.27882305153592285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.27882305153592285"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_computer(logits_i,logits_j, cosine=False, k=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap=0.4969256156384869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4969256156384869"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_computer(softmx_i,softmx_j, cosine=False, k=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap=0.35662553947702463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35662553947702463"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_computer(softmx_i_norm,softmx_j_norm, cosine=False, k=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_index_i = np.argmax(logits_i,axis=1)\n",
    "mx_index_j = np.argmax(logits_j,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmx_i = np.zeros([4524,3200])\n",
    "argmx_i[mx_index_i] = 1\n",
    "argmx_j = np.zeros([4524,3200])\n",
    "argmx_j[mx_index_j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37634236"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(softmx_i[0]-softmx_j[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4524, 32000)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmx_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(softmx_i,maxk=1000)\n",
    "overlap = data.return_data_overlap(softmx_j, k=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48004288240495135"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
