{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd4bb853-1a25-4bcd-86f3-a034e98f2aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/u/dssc/zenocosini/helm_suite/MCQA_Benchmark\")\n",
    "from dadapy.data import Data\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "from common.conifg_plot import ConfigPlotSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84a3cdaa-da9f-43a9-9deb-0f9e41ce843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_composition(cluster_indices, index_to_subject, subject_relevance):\n",
    "    # subject integer identifier: frequency of the subjects\n",
    "    counts = Counter(np.array(cluster_indices) // 100)\n",
    "    # total_number of points in the cluster\n",
    "    population = len(cluster_indices)\n",
    "\n",
    "    # all subjects contained in a cluster\n",
    "    clust_subjects = [index_to_subject[t[0]] for t in counts.most_common()]\n",
    "\n",
    "    clust_percent = [t[1] / population for t in counts.most_common()]\n",
    "\n",
    "    assert np.sum(clust_percent) > 0.9999, (clust_percent, np.sum(clust_percent))\n",
    "\n",
    "    class_to_count = []\n",
    "    current_perc = 0\n",
    "\n",
    "    #\n",
    "    for i in range(len(clust_subjects)):\n",
    "        current_perc += clust_percent[i]\n",
    "        # we consider a subject relevant only iif its presence is >0.2 the maximum popolated class\n",
    "        if clust_percent[i] / clust_percent[0] > subject_relevance:\n",
    "            class_to_count.append(clust_subjects[i])\n",
    "        if current_perc > 0.9:\n",
    "            break\n",
    "\n",
    "    if clust_percent[0] < 0.3 or len(class_to_count) > 3:\n",
    "        class_to_count = [f\"mix of {len(class_to_count)} subjects\"]\n",
    "\n",
    "    return clust_subjects, clust_percent, class_to_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c5ad462f-b523-464f-8826-4841f45d221d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/orfeo/cephfs/scratch/area/ddoimo/open/geometric_lens/repo/results/llama-3-70b//llama-3-70b/4shot/statistics_target.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[234], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama-3-70b\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m dirpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnshots\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdirpath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/statistics_target.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      9\u001b[0m     stats \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Creating mask\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mcqa/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/orfeo/cephfs/scratch/area/ddoimo/open/geometric_lens/repo/results/llama-3-70b//llama-3-70b/4shot/statistics_target.pkl'"
     ]
    }
   ],
   "source": [
    "base_dir = \"/orfeo/cephfs/scratch/area/ddoimo/open/geometric_lens/repo/results/llama-3-70b/\"\n",
    "\n",
    "nshots = \"4shot\"\n",
    "layer = 7\n",
    "model = \"llama-3-70b\"\n",
    "dirpath = f\"{base_dir}/{model}/{nshots}\"\n",
    "\n",
    "with open(f\"{dirpath}/statistics_target.pkl\", \"rb\") as f:\n",
    "    stats = pickle.load(f)\n",
    "    \n",
    "# Creating mask\n",
    "nsamples_per_subject = 100 # number of instance per sub\n",
    "def select_rows(group):\n",
    "    return group.head(min(len(group), nsamples_per_subject))\n",
    "    \n",
    "series = pd.Series(stats['subjects'])\n",
    "series_crop = series.groupby(by=series ).apply(select_rows)\n",
    "mask = series_crop.index.get_level_values(1).values\n",
    "\n",
    "# we need to take just 100 samples per class (for simplicity)\n",
    "subjects = np.array(stats[\"subjects\"])\n",
    "frequences = Counter(np.array(stats[\"subjects\"])[mask]).values()\n",
    "# assert len(np.unique(list(frequences))) == 1\n",
    "# assert np.unique(list(frequences))[0] == nsamples_per_subject, np.unique(\n",
    "    # list(frequences)\n",
    "# )[0]\n",
    "\n",
    "\n",
    "subjects = np.array(stats[\"subjects\"])[mask]\n",
    "# ground truth labels array where an integer corresponds to each subject\n",
    "# this ground truth label array should be (carefully!) adapted for cases\n",
    "# in which we do not have an equal number of samples per class\n",
    "\n",
    "gtl = np.repeat(np.arange(57), nsamples_per_subject)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae820d56-ebf5-4879-84a0-d84969c3d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.load(f\"{dirpath}/l{layer}_target.pt\")\n",
    "X = X.to(torch.float64).numpy()[mask]\n",
    "\n",
    "# check we do not have opverlapping datapoints in case ramove tham from the relevant arrays\n",
    "X_, indx, inverse = np.unique(X, axis=0, return_inverse=True, return_index=True)\n",
    "sorted_indx = np.sort(indx)\n",
    "X_sub = X[sorted_indx]\n",
    "gtl = gtl[sorted_indx]\n",
    "subjects = subjects[sorted_indx]\n",
    "\n",
    "\n",
    "# mapping indices to subjects\n",
    "index_to_subject = {}\n",
    "for i in range(len(gtl)):\n",
    "    if gtl[i] in index_to_subject:\n",
    "        assert index_to_subject[gtl[i]] == subjects[i], (i, gtl[i], subjects[i])\n",
    "    else:\n",
    "        index_to_subject[gtl[i]] = subjects[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375da4ec-0ac8-417e-a376-becdc1068ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ************************************************************************\n",
    "# here we should try also halo = True\n",
    "d = Data(coordinates=X_sub, maxk=300)\n",
    "ids, _, _ = d.return_id_scaling_gride(range_max=300)\n",
    "d.set_id(ids[4])\n",
    "# d.return_id_scaling_gride(range_max=100)\n",
    "# d.compute_density_PAk()\n",
    "d.compute_density_kNN(k=32)\n",
    "cluster_assignment = d.compute_clustering_ADP(Z=1.68, halo=True)\n",
    "is_core = cluster_assignment != -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd0faf2-c4e1-4853-af4f-08053d4b5ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **************************************************************\n",
    "# we consider only clusters with at least 30 points (this can be relaxed or decreased)\n",
    "min_population = 1\n",
    "\n",
    "cluster_mask = []\n",
    "final_clusters_tmp = []\n",
    "for cluster_indices in d.cluster_indices:\n",
    "    if len(cluster_indices) > min_population:\n",
    "        cluster_mask.append(True)\n",
    "        final_clusters_tmp.append(cluster_indices)\n",
    "    else:\n",
    "        cluster_mask.append(False)\n",
    "\n",
    "cluster_mask = np.array(cluster_mask)\n",
    "assert cluster_mask.shape[0] == d.N_clusters\n",
    "\n",
    "\n",
    "final_clusters = final_clusters_tmp\n",
    "nclus = len(final_clusters)\n",
    "assert nclus == np.sum(cluster_mask)\n",
    "saddle_densities = d.log_den_bord[cluster_mask]\n",
    "saddle_densities = saddle_densities[:, cluster_mask]\n",
    "density_peak_indices = np.array(d.cluster_centers)[cluster_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b559732-4260-4a2f-8748-f169603b2f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************\n",
    "# pivotal similrity matrices of the clusters with a population > min_population\n",
    "\n",
    "# key quantity for the dendogram is here: similarity matrix given by the density\n",
    "# default from the advanced density peak paper. Other similarities can be tried in a second phase.\n",
    "density_peaks = d.log_den[density_peak_indices]\n",
    "Fmax = max(density_peaks)\n",
    "Dis = []\n",
    "for i in range(nclus):\n",
    "    for j in range(i + 1, nclus):\n",
    "        Dis.append(Fmax - saddle_densities[i][j])\n",
    "\n",
    "\n",
    "# similar clusters are those whic are closer \"small distance\".\n",
    "# we subtract the saddle point density to the max density peak highest saddles --> close categories\n",
    "Dis = np.array(Dis)\n",
    "# methods: 'single', 'complete', 'average', 'weighted', 'centroid'\n",
    "DD = sp.cluster.hierarchy.linkage(Dis, method=\"weighted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20abd0e-25d9-48ed-8aa4-22a4d214abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ************************************************************************\n",
    "# get subjects in the final clusters\n",
    "\n",
    "# we consider a subject relevant in a cluster only if it has a frequancy 0.2*the most present class\n",
    "subject_relevance = 0.2\n",
    "clust_subjects = defaultdict(list)\n",
    "clust_approx_subjects = defaultdict(list)\n",
    "clust_percent = defaultdict(list)\n",
    "\n",
    "for i in range(len(final_clusters)):\n",
    "    sub, comp, approx = get_composition(\n",
    "        final_clusters[i], index_to_subject, subject_relevance\n",
    "    )\n",
    "    clust_subjects[i] = sub\n",
    "    clust_approx_subjects[i] = approx\n",
    "    clust_percent[i] = comp\n",
    "\n",
    "\n",
    "labels = []\n",
    "for i, (clust, subjects) in enumerate(clust_approx_subjects.items()):\n",
    "    name = \"\"\n",
    "    for sub in subjects:\n",
    "        name += f\" {sub},\"\n",
    "    labels.append(name.strip()[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca37c5ee-ea93-4891-8ccf-10970160dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************************\n",
    "thr = 10  # color threshold\n",
    "conf_size = ConfigPlotSize\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(conf_size.width, conf_size.height))  # create figure & 1 axis\n",
    "# truncate_mode: 'lastp', 'level', None\n",
    "# labels = lab\n",
    "params = {'legend.fontsize': conf_size.legend,\n",
    "          'figure.figsize': (conf_size.width, conf_size.height),\n",
    "         'axes.labelsize': conf_size.xlabel,\n",
    "         'axes.titlesize':conf_size.title,\n",
    "         'xtick.labelsize':conf_size.xticks,\n",
    "         'ytick.labelsize':2}\n",
    "dn = sp.cluster.hierarchy.dendrogram(\n",
    "    DD,\n",
    "    p=32,\n",
    "    truncate_mode=None,\n",
    "    color_threshold=thr,\n",
    "    get_leaves=True,\n",
    "    orientation=\"left\",\n",
    "    above_threshold_color=\"b\",\n",
    "    labels=labels,\n",
    ")\n",
    "plt.rcParams.update(params)\n",
    "ax.tick_params(axis='y', which='major', labelsize=conf_size.xticks)\n",
    "plt.tight_layout()\n",
    "fig.savefig(f\"dendogram/{nsamples_per_subject}/dendogram_{model}_layer_{layer}_{nshots}.png\", dpi=150)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d98498-0fc5-4cc8-8818-cf8d2d719ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
