{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69a4a1e7-ccd7-41c0-8062-b22014e134a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary library\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65b94f7-c3c7-480e-a86a-69fc54135f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [\"mmlu:abstract_algebra\", \n",
    "            \"mmlu:anatomy\", \n",
    "            \"mmlu:astronomy\", \n",
    "            \"mmlu:business_ethics\",\n",
    "            \"mmlu:clinical_knowledge\",\n",
    "            \"mmlu:college_biology\",\n",
    "            \"mmlu:college_chemistry\",\n",
    "            \"mmlu:college_computer_science\",\n",
    "            \"mmlu:college_mathematics\",\n",
    "            \"mmlu:college_medicine\",\n",
    "            \"mmlu:college_physics\",\n",
    "            \"mmlu:computer_security\",\n",
    "            \"mmlu:conceptual_physics\",\n",
    "            \"mmlu:econometrics\",\n",
    "            \"mmlu:electrical_engineering\",\n",
    "            \"mmlu:elementary_mathematics\",\n",
    "            \"mmlu:formal_logic\",\n",
    "            \"mmlu:global_facts\",\n",
    "            \"mmlu:high_school_biology\",\n",
    "            \"mmlu:high_school_chemistry\",\n",
    "            \"mmlu:high_school_computer_science\",\n",
    "            \"mmlu:high_school_european_history\",\n",
    "            \"mmlu:high_school_geography\",\n",
    "            \"mmlu:high_school_government_and_politics\",\n",
    "            \"mmlu:high_school_macroeconomics\",\n",
    "            \"mmlu:high_school_mathematics\",\n",
    "            \"mmlu:high_school_microeconomics\",\n",
    "            \"mmlu:high_school_physics\",\n",
    "            \"mmlu:high_school_psychology\",\n",
    "            \"mmlu:high_school_statistics\",\n",
    "            \"mmlu:high_school_us_history\",\n",
    "            \"mmlu:high_school_world_history\",\n",
    "            \"mmlu:human_aging\",\n",
    "            \"mmlu:human_sexuality\",\n",
    "            \"mmlu:international_law\",\n",
    "            \"mmlu:jurisprudence\",\n",
    "            \"mmlu:logical_fallacies\",\n",
    "            \"mmlu:machine_learning\",\n",
    "            \"mmlu:management\",\n",
    "            \"mmlu:marketing\",\n",
    "            \"mmlu:medical_genetics\",\n",
    "            \"mmlu:miscellaneous\",\n",
    "            \"mmlu:moral_disputes\",\n",
    "            \"mmlu:moral_scenarios\",\n",
    "            \"mmlu:nutrition\",\n",
    "            \"mmlu:philosophy\",\n",
    "            \"mmlu:prehistory\",\n",
    "            \"mmlu:professional_accounting\",\n",
    "            \"mmlu:professional_law\",\n",
    "            \"mmlu:professional_medicine\",\n",
    "            \"mmlu:professional_psychology\",\n",
    "            \"mmlu:public_relations\",\n",
    "            \"mmlu:security_studies\",\n",
    "            \"mmlu:sociology\",\n",
    "            \"mmlu:us_foreign_policy\",\n",
    "            \"mmlu:virology\",\n",
    "            \"mmlu:world_religions\"]\n",
    "subjects = [sub[5:] for sub in subjects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f8765ba-64ee-4667-98b1-3c7a1403c0c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting subject: 100%|██████████████████████████| 57/57 [02:49<00:00,  2.97s/it]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'affirmative_prompt/mmlu_val_full.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maffirmative_prompt/mmlu_val_full.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Save all formatted instances to a text file\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m transformed_instances:\n\u001b[1;32m     36\u001b[0m         file\u001b[38;5;241m.\u001b[39mwrite(line \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mcqa/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'affirmative_prompt/mmlu_val_full.txt'"
     ]
    }
   ],
   "source": [
    "# List to hold the formatted strings\n",
    "transformed_instances = []\n",
    "lenght = {}\n",
    "counter = 1\n",
    "subject_val = []\n",
    "for subject in tqdm(subjects, desc=\"Formatting subject\"):\n",
    "    # Load the MMLU dataset\n",
    "    dataset = load_dataset(\"Stevross/mmlu\",subject, split=\"validation\")\n",
    "    \n",
    "    # Iterate through each instance in the dataset\n",
    "    for n,instance in enumerate(dataset):\n",
    "        if n >= 15:\n",
    "            break\n",
    "        question = instance['question']\n",
    "        choices = instance['choices']\n",
    "        answer_key = instance['answer']\n",
    "        \n",
    "        # Find the correct answer using the answerKey\n",
    "        correct_answer = choices[answer_key]\n",
    "        subject_val.append(subject)\n",
    "        # Format the instance into \"Question: ... Answer: ...\"\n",
    "        formatted_string = f\"{counter}: Question: {question}\\n\"\n",
    "        for choice, letter in zip(choices, [\"A\",\"B\",\"C\",\"D\"]):\n",
    "            formatted_string += f\"{letter}. {choice}\\n\"\n",
    "        formatted_string += f\"Answer: {correct_answer}\\n------\"\n",
    "        transformed_instances.append(formatted_string)\n",
    "        counter += 1\n",
    "        \n",
    "    lenght[subject] = n\n",
    "# Path where the output will be saved\n",
    "output_file_path = 'affirmative_prompt/mmlu_val_full.txt'\n",
    "\n",
    "# Save all formatted instances to a text file\n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "    for line in transformed_instances:\n",
    "        file.write(line + '\\n')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6865e50a-4e04-4641-8c81-e1ee2dabed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where the output will be saved\n",
    "output_file_path = 'mmlu_val_full.txt'\n",
    "\n",
    "# Save all formatted instances to a text file\n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "    for line in transformed_instances:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50b5610d-ee7f-4e16-988b-6dd38a438412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "780"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subject_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ad9ee95-32ca-4237-af02-a5fb301685e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all formatted instances to a text file\n",
    "import pickle\n",
    "output_file_path = 'subject_val.pkl'\n",
    "with open(output_file_path, 'wb') as file:\n",
    "    pickle.dump(subject_val, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b99c628-530d-4b4a-8dbf-7501f9abb0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/zenocosini/helm_suite/MCQA_Benchmark/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
